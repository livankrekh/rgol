{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 801), (50000, 401), (50000, 400))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('resources/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('resources/test.csv', index_col=0)\n",
    "sub_df = pd.read_csv('resources/sampleSubmission.csv', index_col=0)\n",
    "df.shape, test_df.shape, sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000,), (50000, 400), (50000, 20, 20))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = df.iloc[:, 0]\n",
    "Y = df.iloc[:, 1:401].values\n",
    "X = df.iloc[:, 401:].values.reshape(-1, 20, 20)\n",
    "delta.shape, Y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5]\n",
      "[2/5]\n",
      "[3/5]\n",
      "[4/5]\n",
      "[5/5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Usage example:\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    kernel_size = 1 + i * 2\n",
    "    print(f\"[{i}/5]\")\n",
    "    X_i = X[delta == i]\n",
    "    Y_i = Y[delta == i]\n",
    "    \n",
    "    X_train, Y_train = prepare_data(X_i, Y_i, kernel_size=kernel_size)\n",
    "\n",
    "    lr = LogisticRegression(random_state=42, solver='lbfgs', max_iter=300)\n",
    "    lr.fit(X_train, Y_train)\n",
    "    models.append(lr)\n",
    "\n",
    "    X_test = test_df[test_df.delta == i]\n",
    "    X_test = X_test.iloc[:, 1:]\n",
    "    X_test_windows = df_to_windows(X_test.values, kernel_size=kernel_size)\n",
    "\n",
    "    test_predictions = lr.predict(X_test_windows)\n",
    "    test_predictions = test_predictions.reshape(-1, 400)\n",
    "    sub_df[test_df.delta == i] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"lr_submission.csv\")  # 0.14386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   10.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   14.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Usage example:\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    kernel_size = 1 + i * 2\n",
    "    print(f\"[{i}/5]\")\n",
    "    X_i = X[delta == i]\n",
    "    Y_i = Y[delta == i]\n",
    "    \n",
    "    X_train, Y_train = prepare_data(X_i, Y_i, kernel_size=kernel_size)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=15, random_state=42, verbose=True, n_jobs=-1)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    models.append(rf)\n",
    "\n",
    "    X_test = test_df[test_df.delta == i]\n",
    "    X_test = X_test.iloc[:, 1:]\n",
    "    X_test_windows = df_to_windows(X_test.values, kernel_size=kernel_size)\n",
    "\n",
    "    test_predictions = rf.predict(X_test_windows)\n",
    "    test_predictions = test_predictions.reshape(-1, 400)\n",
    "    sub_df[test_df.delta == i] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"rf_submission.csv\")  # 0.13300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Usage example:\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    kernel_size = 5\n",
    "    print(f\"[{i}/5]\")\n",
    "    X_i = X[delta == i]\n",
    "    Y_i = Y[delta == i]\n",
    "    \n",
    "    X_train, Y_train = prepare_data(X_i, Y_i, kernel_size=kernel_size)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=15, random_state=42, verbose=True, n_jobs=-1)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    models.append(rf)\n",
    "\n",
    "    X_test = test_df[test_df.delta == i]\n",
    "    X_test = X_test.iloc[:, 1:]\n",
    "    X_test_windows = df_to_windows(X_test.values, kernel_size=kernel_size)\n",
    "\n",
    "    test_predictions = rf.predict(X_test_windows)\n",
    "    test_predictions = test_predictions.reshape(-1, 400)\n",
    "    sub_df[test_df.delta == i] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"rf_submission_kernel_5.csv\") # 0.13221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.7min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.4min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Usage example:\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    kernel_size = 5\n",
    "    print(f\"[{i}/5]\")\n",
    "    X_i = X[delta == i]\n",
    "    Y_i = Y[delta == i]\n",
    "    \n",
    "    X_train, Y_train = prepare_data(X_i, Y_i, kernel_size=kernel_size)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, verbose=True, n_jobs=-1)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    models.append(rf)\n",
    "\n",
    "    X_test = test_df[test_df.delta == i]\n",
    "    X_test = X_test.iloc[:, 1:]\n",
    "    X_test_windows = df_to_windows(X_test.values, kernel_size=kernel_size)\n",
    "\n",
    "    test_predictions = rf.predict(X_test_windows)\n",
    "    test_predictions = test_predictions.reshape(-1, 400)\n",
    "    sub_df[test_df.delta == i] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"rf_submission_kernel_5_100.csv\") # 0.12946"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
